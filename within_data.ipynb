{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "within_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuwShpjYnwotSYcOlvwKL/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achrisk/Dissertation/blob/main/within_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTJZmowrd5sX",
        "outputId": "ba02294b-71d2-4ee7-9fc6-d023da2c8653"
      },
      "source": [
        "!git clone https://github.com/sagihaider/EEG_Deep.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EEG_Deep'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 517 (delta 22), reused 0 (delta 0), pack-reused 477\u001b[K\n",
            "Receiving objects: 100% (517/517), 1.69 GiB | 30.16 MiB/s, done.\n",
            "Resolving deltas: 100% (252/252), done.\n",
            "Checking out files: 100% (95/95), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ggxmna_d9u8"
      },
      "source": [
        "import scipy.io as spio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from importlib.machinery import SourceFileLoader\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from EEG_Deep.EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import butter, lfilter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEGRbemoeAzt"
      },
      "source": [
        "# Band-pass Filter\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wkTcjdRVeA2j",
        "outputId": "2fffe698-254c-43fd-fb6d-8bf970d5c277"
      },
      "source": [
        "from numpy import zeros\n",
        "K.clear_session()\n",
        "\n",
        "X_tr = np.empty([80, 12, 4096])\n",
        "X_ts = np.empty([40, 12, 4096])\n",
        "result=[]\n",
        "\n",
        "h_cut = [24]\n",
        "drop_out = [0.25]\n",
        "k_len = [32, 64, 128]\n",
        "n_epochs = 500\n",
        "\n",
        "outfname = 'accuray_epochs' + str(n_epochs) + '_filter_' + str(h_cut) + '_drop_' + str(drop_out) + '_patient_data.npy'\n",
        "\n",
        "nsub = 10\n",
        "nfilt = len(h_cut)\n",
        "ndrop = len(drop_out)\n",
        "nkl = len(k_len)\n",
        "acc_sub = zeros([nsub, nfilt,ndrop,nkl])\n",
        "\n",
        "for sub_idx, x in enumerate(range(1,11)):\n",
        "    for h_indx, h in enumerate(h_cut):\n",
        "        fName = 'EEG_Deep/Data2A/parsed_P0' + str(x) + 'T.mat'  # Load Data\n",
        "        print(fName)\n",
        "        mat = spio.loadmat(fName)\n",
        "        r_X_tr = mat['RawEEGData']\n",
        "        y_tr = mat['Labels']\n",
        "        y_tr = y_tr.flatten() \n",
        "\n",
        "        print(np.shape(r_X_tr))\n",
        "        print(np.shape(y_tr))\n",
        "\n",
        "        for t in range(r_X_tr.shape[0]):\n",
        "            tril = r_X_tr[t,:,:]\n",
        "            #tril = tril.transpose()\n",
        "            tril_filtered = butter_bandpass_filter(tril, lowcut=8, highcut=h, fs=250, order=4)\n",
        "            # tril_filtered = tril_filtered.transpose()\n",
        "            X_tr[t,:,:] = tril_filtered \n",
        "\n",
        "            # split data of each subject in training and validation\n",
        "        X_train      = X_tr[0:60,:,2048:3584]\n",
        "        Y_train      = y_tr[0:60]\n",
        "        X_val       = X_tr[60:,:,2048:3584]\n",
        "        Y_val       = y_tr[60:]\n",
        "\n",
        "        print(np.shape(X_train))\n",
        "        print(np.shape(Y_train))\n",
        "        print(np.shape(X_val))\n",
        "        print(np.shape(Y_val))\n",
        "\n",
        "        # convert labels to one-hot encodings.\n",
        "        Y_train = np_utils.to_categorical(Y_train-1, num_classes=2)\n",
        "        Y_val = np_utils.to_categorical(Y_val-1, num_classes=2)\n",
        "\n",
        "        kernels, chans, samples = 1, 12, 1536\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_train      = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "        X_val       = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_train.shape)\n",
        "        print(X_train.shape[0], 'train samples')\n",
        "        print(X_val.shape[0], 'val samples')\n",
        "\n",
        "        fName = 'EEG_Deep/Data2A/parsed_P0' + str(x) + 'E.mat'  # Load Data\n",
        "        print(fName)\n",
        "        mat = spio.loadmat(fName)\n",
        "        r_X_ts = mat['RawEEGData']\n",
        "        y_ts = mat['Labels']\n",
        "        y_ts = y_ts.flatten() \n",
        "\n",
        "        print(np.shape(r_X_ts))\n",
        "        print(np.shape(y_ts))\n",
        "\n",
        "        for t in range(r_X_ts.shape[0]):\n",
        "            tril = r_X_ts[t,:,:]\n",
        "            # tril = tril.transpose()\n",
        "            tril_filtered = butter_bandpass_filter(tril, lowcut=8, highcut=h, fs=250, order=4)\n",
        "            # tril_filtered = tril_filtered.transpose()\n",
        "            X_ts[t,:,:] = tril_filtered \n",
        "\n",
        "        X_test      = X_ts[:,:,2048:3584]\n",
        "        Y_test      = y_ts[:]\n",
        "        print(np.shape(X_test))\n",
        "        print(np.shape(Y_test))\n",
        "\n",
        "        #convert labels to one-hot encodings.\n",
        "        Y_test      = np_utils.to_categorical(Y_test-1)\n",
        "\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_test      = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_test.shape)\n",
        "        print(X_test.shape[0], 'test samples')\n",
        "\n",
        "        kernels, chans, samples = 1, 12, 1536\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_train = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "        X_val   = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_train.shape)\n",
        "        print(X_train.shape[0], 'train samples')\n",
        "        print(X_val.shape[0], 'val samples')\n",
        "\n",
        "        X_test      = X_ts[:,:,2048:3584]\n",
        "        Y_test      = y_ts[:]\n",
        "        print(np.shape(X_test))\n",
        "        print(np.shape(Y_test))\n",
        "\n",
        "        #convert labels to one-hot encodings.\n",
        "        Y_test      = np_utils.to_categorical(Y_test-1, num_classes=2)\n",
        "\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_test      = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_test.shape)\n",
        "        print(X_test.shape[0], 'train samples')\n",
        "\n",
        "        # acc_sub = zeros([rows, cols])\n",
        "        for id_d, d in enumerate(drop_out):\n",
        "            for id_kl, kl in enumerate(k_len):\n",
        "              print(id_kl, id_d)\n",
        "              # configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
        "              # model configurations may do better, but this is a good starting point)\n",
        "              model = EEGNet(nb_classes = 2, Chans = 12, Samples = 1536,\n",
        "                             dropoutRate = d, kernLength = kl, F1 = 8,D = 2, F2 = 16,\n",
        "                             norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "\n",
        "              # compile the model and set the optimizers\n",
        "              model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "                            metrics = ['accuracy'])\n",
        "\n",
        "              # count number of parameters in the model\n",
        "              numParams    = model.count_params() \n",
        "\n",
        "              # set a valid path for your system to record model checkpoints\n",
        "              checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "              # the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
        "              # the weights all to be 1\n",
        "              class_weights = {0:1, 1:1}\n",
        "\n",
        "              history = model.fit(X_train, Y_train, batch_size = 16, epochs = n_epochs, \n",
        "                                  verbose = 2, validation_data=(X_val, Y_val),\n",
        "                                  callbacks=[checkpointer], class_weight = class_weights)\n",
        "\n",
        "              print('\\n# Evaluate on test data')\n",
        "              results = model.evaluate(X_test, Y_test, batch_size=1)\n",
        "              print('test loss, test acc:', results)\n",
        "\n",
        "              acc_sub[sub_idx,h_indx,id_d, id_kl] = results[1]\n",
        "\n",
        "              from keras import backend as K \n",
        "              # Do some code, e.g. train and save model\n",
        "              K.clear_session()\n",
        "              \n",
        "np.save(outfname, acc_sub)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(80, 12, 4096)\n",
            "(80,)\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "EEG_Deep/Data2A/parsed_P01E.mat\n",
            "(40, 12, 4096)\n",
            "(40,)\n",
            "(40, 12, 1536)\n",
            "(40,)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 test samples\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40,)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.83718, saving model to /tmp/checkpoint.h5\n",
            "4/4 - 0s - loss: 0.6877 - accuracy: 0.5667 - val_loss: 0.8372 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.5974 - accuracy: 0.6667 - val_loss: 0.9586 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.5780 - accuracy: 0.6667 - val_loss: 1.0217 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.5558 - accuracy: 0.6667 - val_loss: 1.0669 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.5534 - accuracy: 0.6667 - val_loss: 1.1115 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.5394 - accuracy: 0.6667 - val_loss: 1.1501 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.5110 - accuracy: 0.6667 - val_loss: 1.2129 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.4923 - accuracy: 0.7167 - val_loss: 1.2878 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.4805 - accuracy: 0.7500 - val_loss: 1.3926 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.4497 - accuracy: 0.8500 - val_loss: 1.5473 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.4434 - accuracy: 0.8167 - val_loss: 1.7172 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.4193 - accuracy: 0.8667 - val_loss: 1.9003 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.4097 - accuracy: 0.8833 - val_loss: 2.1017 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3994 - accuracy: 0.9000 - val_loss: 2.3344 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3871 - accuracy: 0.9000 - val_loss: 2.5551 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3589 - accuracy: 0.8667 - val_loss: 2.8017 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3579 - accuracy: 0.8833 - val_loss: 3.0638 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3414 - accuracy: 0.9000 - val_loss: 3.3046 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3399 - accuracy: 0.9000 - val_loss: 3.5459 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3648 - accuracy: 0.8333 - val_loss: 3.7501 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3412 - accuracy: 0.8333 - val_loss: 3.9406 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3131 - accuracy: 0.9333 - val_loss: 4.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3320 - accuracy: 0.8667 - val_loss: 4.2951 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3224 - accuracy: 0.9000 - val_loss: 4.4567 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2807 - accuracy: 0.9167 - val_loss: 4.5553 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3188 - accuracy: 0.9000 - val_loss: 4.6498 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2809 - accuracy: 0.9167 - val_loss: 4.7986 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.3450 - accuracy: 0.8667 - val_loss: 4.9151 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2960 - accuracy: 0.9333 - val_loss: 5.0323 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2796 - accuracy: 0.9167 - val_loss: 5.1181 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2877 - accuracy: 0.9500 - val_loss: 5.2539 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2901 - accuracy: 0.8833 - val_loss: 5.2443 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2723 - accuracy: 0.9333 - val_loss: 5.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2765 - accuracy: 0.9000 - val_loss: 5.4497 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2483 - accuracy: 0.9500 - val_loss: 5.5252 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2729 - accuracy: 0.9167 - val_loss: 5.5748 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2932 - accuracy: 0.8500 - val_loss: 5.6258 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2472 - accuracy: 0.9000 - val_loss: 5.6522 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2669 - accuracy: 0.9000 - val_loss: 5.6968 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2562 - accuracy: 0.9167 - val_loss: 5.6809 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2719 - accuracy: 0.9500 - val_loss: 5.6767 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2276 - accuracy: 0.9167 - val_loss: 5.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2730 - accuracy: 0.9000 - val_loss: 5.6125 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2991 - accuracy: 0.8667 - val_loss: 5.5497 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2170 - accuracy: 0.9333 - val_loss: 5.4931 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2337 - accuracy: 0.9500 - val_loss: 5.4516 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2523 - accuracy: 0.9500 - val_loss: 5.4529 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2306 - accuracy: 0.9667 - val_loss: 5.5154 - val_accuracy: 0.1000\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2090 - accuracy: 0.9667 - val_loss: 5.5502 - val_accuracy: 0.1000\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2038 - accuracy: 0.9500 - val_loss: 5.6184 - val_accuracy: 0.1500\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2052 - accuracy: 0.9500 - val_loss: 5.6484 - val_accuracy: 0.1500\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2071 - accuracy: 0.9667 - val_loss: 5.7041 - val_accuracy: 0.2500\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2190 - accuracy: 0.9167 - val_loss: 5.6926 - val_accuracy: 0.2500\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1828 - accuracy: 0.9833 - val_loss: 5.6624 - val_accuracy: 0.3500\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1973 - accuracy: 0.9667 - val_loss: 5.7086 - val_accuracy: 0.3500\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2510 - accuracy: 0.8667 - val_loss: 5.7306 - val_accuracy: 0.3500\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2057 - accuracy: 0.9500 - val_loss: 5.6881 - val_accuracy: 0.3500\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2143 - accuracy: 0.9500 - val_loss: 5.6696 - val_accuracy: 0.3500\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2196 - accuracy: 0.9333 - val_loss: 5.5851 - val_accuracy: 0.3500\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2228 - accuracy: 0.9333 - val_loss: 5.5487 - val_accuracy: 0.3500\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2288 - accuracy: 0.9167 - val_loss: 5.3834 - val_accuracy: 0.3500\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1887 - accuracy: 0.9333 - val_loss: 5.2606 - val_accuracy: 0.4500\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2091 - accuracy: 0.9333 - val_loss: 5.2163 - val_accuracy: 0.5000\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1976 - accuracy: 0.9333 - val_loss: 5.2558 - val_accuracy: 0.5000\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2034 - accuracy: 0.9833 - val_loss: 5.2695 - val_accuracy: 0.5000\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2112 - accuracy: 0.9333 - val_loss: 5.2057 - val_accuracy: 0.5000\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1837 - accuracy: 0.9833 - val_loss: 5.2782 - val_accuracy: 0.5000\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2127 - accuracy: 0.9000 - val_loss: 5.2913 - val_accuracy: 0.5000\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2048 - accuracy: 0.9833 - val_loss: 5.3521 - val_accuracy: 0.5000\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1667 - accuracy: 0.9667 - val_loss: 5.4412 - val_accuracy: 0.5000\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2237 - accuracy: 0.9000 - val_loss: 5.5117 - val_accuracy: 0.5000\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1862 - accuracy: 0.9667 - val_loss: 5.5872 - val_accuracy: 0.5000\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1775 - accuracy: 0.9333 - val_loss: 5.6494 - val_accuracy: 0.5000\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2153 - accuracy: 0.9333 - val_loss: 5.7134 - val_accuracy: 0.5000\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1917 - accuracy: 0.9500 - val_loss: 5.6916 - val_accuracy: 0.5000\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2335 - accuracy: 0.8833 - val_loss: 5.6461 - val_accuracy: 0.5000\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1909 - accuracy: 0.9333 - val_loss: 5.6278 - val_accuracy: 0.5000\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1843 - accuracy: 0.9500 - val_loss: 5.5996 - val_accuracy: 0.5000\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1555 - accuracy: 0.9500 - val_loss: 5.6220 - val_accuracy: 0.5000\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1809 - accuracy: 0.9333 - val_loss: 5.6020 - val_accuracy: 0.5000\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1692 - accuracy: 0.9833 - val_loss: 5.5515 - val_accuracy: 0.5000\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1596 - accuracy: 0.9667 - val_loss: 5.5851 - val_accuracy: 0.5000\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1498 - accuracy: 1.0000 - val_loss: 5.5910 - val_accuracy: 0.5000\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1526 - accuracy: 0.9500 - val_loss: 5.6081 - val_accuracy: 0.5000\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1589 - accuracy: 0.9833 - val_loss: 5.6150 - val_accuracy: 0.5000\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1821 - accuracy: 0.9667 - val_loss: 5.5970 - val_accuracy: 0.5000\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1583 - accuracy: 0.9667 - val_loss: 5.5268 - val_accuracy: 0.5000\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1330 - accuracy: 0.9833 - val_loss: 5.5547 - val_accuracy: 0.5000\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.2027 - accuracy: 0.9167 - val_loss: 5.4187 - val_accuracy: 0.5000\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1439 - accuracy: 0.9833 - val_loss: 5.2254 - val_accuracy: 0.5000\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1479 - accuracy: 0.9833 - val_loss: 5.1279 - val_accuracy: 0.5500\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1396 - accuracy: 1.0000 - val_loss: 5.0591 - val_accuracy: 0.5500\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1373 - accuracy: 1.0000 - val_loss: 5.0755 - val_accuracy: 0.5500\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1395 - accuracy: 0.9833 - val_loss: 5.0629 - val_accuracy: 0.5500\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1808 - accuracy: 0.9667 - val_loss: 4.9637 - val_accuracy: 0.6000\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1269 - accuracy: 1.0000 - val_loss: 4.9258 - val_accuracy: 0.6000\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1290 - accuracy: 1.0000 - val_loss: 4.9817 - val_accuracy: 0.6000\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1289 - accuracy: 0.9833 - val_loss: 5.0547 - val_accuracy: 0.6000\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1359 - accuracy: 1.0000 - val_loss: 5.0781 - val_accuracy: 0.6000\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1528 - accuracy: 0.9667 - val_loss: 5.0761 - val_accuracy: 0.6000\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1292 - accuracy: 0.9833 - val_loss: 5.0480 - val_accuracy: 0.6000\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1585 - accuracy: 0.9667 - val_loss: 4.9641 - val_accuracy: 0.6000\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.83718\n",
            "4/4 - 0s - loss: 0.1140 - accuracy: 0.9833 - val_loss: 4.8379 - val_accuracy: 0.6000\n",
            "Epoch 104/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-dff17012dada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m               history = model.fit(X_train, Y_train, batch_size = 16, epochs = n_epochs, \n\u001b[1;32m    147\u001b[0m                                   \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                   callbacks=[checkpointer], class_weight = class_weights)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n# Evaluate on test data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqoOs--eA4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9a7Ds3eBAY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D49hSgEkeA9_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsMiBBYIeA8F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}