{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "within_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeXq/ncFTfhoYpwUuNwhiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achrisk/Dissertation/blob/main/within_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTJZmowrd5sX",
        "outputId": "ec40a141-0f52-466a-deb1-09e8fa5ff35b"
      },
      "source": [
        "!git clone https://github.com/achrisk/Dissertation.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dissertation'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 32 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n",
            "Checking out files: 100% (23/23), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ggxmna_d9u8"
      },
      "source": [
        "import scipy.io as spio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from importlib.machinery import SourceFileLoader\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from Dissertation.EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import butter, lfilter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEGRbemoeAzt"
      },
      "source": [
        "# Band-pass Filter\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "wkTcjdRVeA2j",
        "outputId": "2746bc2f-a7db-4cb4-a034-421fc35b3d72"
      },
      "source": [
        "from numpy import zeros\n",
        "K.clear_session()\n",
        "\n",
        "X_tr = np.empty([80, 12, 4096])\n",
        "X_ts = np.empty([40, 12, 4096])\n",
        "result=[]\n",
        "\n",
        "h_cut = [24]\n",
        "drop_out = [0.25]\n",
        "k_len = [32, 64, 128]\n",
        "n_epochs = 500\n",
        "\n",
        "outfname = 'accuray_epochs' + str(n_epochs) + '_filter_' + str(h_cut) + '_drop_' + str(drop_out) + '_patient_data.npy'\n",
        "\n",
        "nsub = 10\n",
        "nfilt = len(h_cut)\n",
        "ndrop = len(drop_out)\n",
        "nkl = len(k_len)\n",
        "acc_sub = zeros([nsub, nfilt,ndrop,nkl])\n",
        "\n",
        "for sub_idx, x in enumerate(range(1,11)):\n",
        "    for h_indx, h in enumerate(h_cut):\n",
        "        fName = 'Dissertation/EEG data/parsed_P0' + str(x) + 'T.mat'  # Load Data\n",
        "        print(fName)\n",
        "        mat = spio.loadmat(fName)\n",
        "        r_X_tr = mat['RawEEGData']\n",
        "        y_tr = mat['Labels']\n",
        "        y_tr = y_tr.flatten() \n",
        "\n",
        "        print(np.shape(r_X_tr))\n",
        "        print(np.shape(y_tr))\n",
        "\n",
        "        for t in range(r_X_tr.shape[0]):\n",
        "            tril = r_X_tr[t,:,:]\n",
        "            #tril = tril.transpose()\n",
        "            tril_filtered = butter_bandpass_filter(tril, lowcut=8, highcut=h, fs=250, order=4)\n",
        "            # tril_filtered = tril_filtered.transpose()\n",
        "            X_tr[t,:,:] = tril_filtered \n",
        "\n",
        "            # split data of each subject in training and validation\n",
        "        X_train      = X_tr[0:60,:,2048:3584]\n",
        "        Y_train      = y_tr[0:60]\n",
        "        X_val       = X_tr[60:,:,2048:3584]\n",
        "        Y_val       = y_tr[60:]\n",
        "\n",
        "        print(np.shape(X_train))\n",
        "        print(np.shape(Y_train))\n",
        "        print(np.shape(X_val))\n",
        "        print(np.shape(Y_val))\n",
        "\n",
        "        # convert labels to one-hot encodings.\n",
        "        Y_train = np_utils.to_categorical(Y_train-1, num_classes=2)\n",
        "        Y_val = np_utils.to_categorical(Y_val-1, num_classes=2)\n",
        "\n",
        "        kernels, chans, samples = 1, 12, 1536\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_train      = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "        X_val       = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_train.shape)\n",
        "        print(X_train.shape[0], 'train samples')\n",
        "        print(X_val.shape[0], 'val samples')\n",
        "\n",
        "        fName = 'Dissertation/EEG data/parsed_P0' + str(x) + 'E.mat'  # Load Data\n",
        "        print(fName)\n",
        "        mat = spio.loadmat(fName)\n",
        "        r_X_ts = mat['RawEEGData']\n",
        "        y_ts = mat['Labels']\n",
        "        y_ts = y_ts.flatten() \n",
        "\n",
        "        print(np.shape(r_X_ts))\n",
        "        print(np.shape(y_ts))\n",
        "\n",
        "        for t in range(r_X_ts.shape[0]):\n",
        "            tril = r_X_ts[t,:,:]\n",
        "            # tril = tril.transpose()\n",
        "            tril_filtered = butter_bandpass_filter(tril, lowcut=8, highcut=h, fs=250, order=4)\n",
        "            # tril_filtered = tril_filtered.transpose()\n",
        "            X_ts[t,:,:] = tril_filtered \n",
        "\n",
        "        X_test      = X_ts[:,:,2048:3584]\n",
        "        Y_test      = y_ts[:]\n",
        "        print(np.shape(X_test))\n",
        "        print(np.shape(Y_test))\n",
        "\n",
        "        #convert labels to one-hot encodings.\n",
        "        Y_test      = np_utils.to_categorical(Y_test-1)\n",
        "\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_test      = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_test.shape)\n",
        "        print(X_test.shape[0], 'test samples')\n",
        "\n",
        "        kernels, chans, samples = 1, 12, 1536\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_train = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "        X_val   = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_train.shape)\n",
        "        print(X_train.shape[0], 'train samples')\n",
        "        print(X_val.shape[0], 'val samples')\n",
        "\n",
        "        X_test      = X_ts[:,:,2048:3584]\n",
        "        Y_test      = y_ts[:]\n",
        "        print(np.shape(X_test))\n",
        "        print(np.shape(Y_test))\n",
        "\n",
        "        #convert labels to one-hot encodings.\n",
        "        Y_test      = np_utils.to_categorical(Y_test-1, num_classes=2)\n",
        "\n",
        "        # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "        # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "        X_test      = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "        print('X_train shape:', X_test.shape)\n",
        "        print(X_test.shape[0], 'train samples')\n",
        "\n",
        "        # acc_sub = zeros([rows, cols])\n",
        "        for id_d, d in enumerate(drop_out):\n",
        "            for id_kl, kl in enumerate(k_len):\n",
        "              print(id_kl, id_d)\n",
        "              # configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
        "              # model configurations may do better, but this is a good starting point)\n",
        "              model = EEGNet(nb_classes = 2, Chans = 12, Samples = 1536,\n",
        "                             dropoutRate = d, kernLength = kl, F1 = 8,D = 2, F2 = 16,\n",
        "                             norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "\n",
        "              # compile the model and set the optimizers\n",
        "              model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "                            metrics = ['accuracy'])\n",
        "\n",
        "              # count number of parameters in the model\n",
        "              numParams    = model.count_params() \n",
        "\n",
        "              # set a valid path for your system to record model checkpoints\n",
        "              checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "              # the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
        "              # the weights all to be 1\n",
        "              class_weights = {0:1, 1:1}\n",
        "\n",
        "              history = model.fit(X_train, Y_train, batch_size = 16, epochs = n_epochs, \n",
        "                                  verbose = 2, validation_data=(X_val, Y_val),\n",
        "                                  callbacks=[checkpointer], class_weight = class_weights)\n",
        "\n",
        "              print('\\n# Evaluate on test data')\n",
        "              results = model.evaluate(X_test, Y_test, batch_size=1)\n",
        "              print('test loss, test acc:', results)\n",
        "\n",
        "              acc_sub[sub_idx,h_indx,id_d, id_kl] = results[1]\n",
        "\n",
        "              from keras import backend as K \n",
        "              # Do some code, e.g. train and save model\n",
        "              K.clear_session()\n",
        "              \n",
        "np.save(outfname, acc_sub)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dissertation/EEG data/parsed_P01T.mat\n",
            "(80, 12, 4096)\n",
            "(80,)\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "Dissertation/EEG data/parsed_P01E.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-36d31c0c0c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mr_X_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RawEEGData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0my_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0my_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_ts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqoOs--eA4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9a7Ds3eBAY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D49hSgEkeA9_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsMiBBYIeA8F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}